{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import gc\n",
    "# This module provides an interface to the optional garbage collector. It provides the ability to disable the collector, tune the collection frequency, \n",
    "# and set debugging options.\n",
    "\n",
    "import re\n",
    "# This module provides regular expression matching operations similar to those found in Perl.\n",
    "\n",
    "import string\n",
    "\n",
    "import operator\n",
    "# The operator module exports a set of efficient functions corresponding to the intrinsic operators of Python. For example, \n",
    "# operator.add(x, y) is equivalent to the expression x+y\n",
    "\n",
    "from collections import defaultdict\n",
    "# This module implements specialized container datatypes providing alternatives to Pythonâ€™s general purpose built-in containers, dict, list, set, and tuple.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set the pandas dataframe to show maximum 500 rows and 500 columns and set the display width to be 1000\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.pyplot is a state-based interface to matplotlib. It provides a MATLAB-like way of plotting.\n",
    "\n",
    "import seaborn as sns\n",
    "# Seaborn is a library for making statistical graphics in Python. It is built on top of matplotlib and closely integrated with pandas data structures.\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile(src = \"../input/tokenization/tokenization.py\", dst = \"tokenization.py\")\n",
    "import tokenization\n",
    "\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Simple and efficient tools for predictive data analysis\n",
    "# Accessible to everybody, and reusable in various contexts\n",
    "# Built on NumPy, SciPy, and matplotlib\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# The core open source library to help you develop and train ML models. Get started quickly by running Colab notebooks directly in your browser.\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# tf.keras is TensorFlow's high-level API for building and training deep learning models. It's used for fast prototyping, state-of-the-art research, and production,\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "\n",
    "import pickle\n",
    "SEED = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the csv file ensuring that the id column is of 16 bit integers and the target column is of 32 bit integers. Remember that the test file doesn't have a target column\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "- Read a comma-separated values (csv) file into DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/nlp-getting-started/train.csv', dtype={'id': np.int16, 'target': np.int8})\n",
    "df_test = pd.read_csv('../input/nlp-getting-started/test.csv', dtype={'id': np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_missing_check= df_train.copy()\n",
    "df_test_missing_check= df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.memory_usage.html\n",
    "* Return the memory usage of each column in bytes.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.sum.html\n",
    "* Return the sum of the values for the requested axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Set Shape = {}'.format(df_train.shape))\n",
    "print(type(df_train.memory_usage()))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(df_test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
