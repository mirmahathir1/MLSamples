{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==1.15 keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./predicted’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!cp -Rf ../input/wheatprediction/WheatPrediction/yolo3 ./\n",
    "!mkdir ./predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import colorsys\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import cv2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import image_preporcess\n",
    "\n",
    "class YOLO(object):\n",
    "    _defaults = {\n",
    "        \"model_path\": '../input/wheatprediction/WheatPrediction/logs/trained_weights_final.h5',\n",
    "        \"anchors_path\": '../input/wheatprediction/WheatPrediction/model_data/yolo_anchors.txt',\n",
    "        \"classes_path\": '../input/wheatprediction/WheatPrediction/4_CLASS_test_classes.txt',\n",
    "        \"score\" : 0.3,\n",
    "        \"iou\" : 0.45,\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"text_size\" : 3,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = image_preporcess(np.copy(image), tuple(reversed(self.model_image_size)))\n",
    "            image_data = boxed_image\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.shape[0], image.shape[1]],#[image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        thickness = (image.shape[0] + image.shape[1]) // 600\n",
    "        fontScale=1\n",
    "        ObjectsList = []\n",
    "        \n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            #label = '{}'.format(predicted_class)\n",
    "            scores = '{:.2f}'.format(score)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.shape[0], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.shape[1], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "            mid_h = (bottom-top)/2+top\n",
    "            mid_v = (right-left)/2+left\n",
    "\n",
    "            # put object rectangle\n",
    "            cv2.rectangle(image, (left, top), (right, bottom), self.colors[c], thickness)\n",
    "\n",
    "            # get text size\n",
    "            (test_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, thickness/self.text_size, 1)\n",
    "\n",
    "            # put text rectangle\n",
    "            cv2.rectangle(image, (left, top), (left + test_width, top - text_height - baseline), self.colors[c], thickness=cv2.FILLED)\n",
    "\n",
    "            # put text above rectangle\n",
    "            cv2.putText(image, label, (left, top-2), cv2.FONT_HERSHEY_SIMPLEX, thickness/self.text_size, (0, 0, 0), 1)\n",
    "\n",
    "            # add everything to list\n",
    "            ObjectsList.append([top, left, bottom, right, mid_v, mid_h, label, scores])\n",
    "\n",
    "        return image, ObjectsList\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "    def detect_img(self, image):\n",
    "        image = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "        original_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        original_image_color = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        r_image, ObjectsList = self.detect_image(original_image_color)\n",
    "        return r_image, ObjectsList\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "../input/wheatprediction/WheatPrediction/logs/trained_weights_final.h5 model, anchors, and classes loaded.\n",
      "WARNING:tensorflow:From /home/mahathir/miniconda3/envs/yolov3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO()\n",
    "# image = '../input/global-wheat-detection/test/2fd875eaa.jpg'\n",
    "# r_image, ObjectsList = yolo.detect_img(image)\n",
    "\n",
    "# cv2.imwrite('predicted/2fd875eaa_prediction.jpg', r_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imShow(path):\n",
    "#   import cv2\n",
    "#   import matplotlib.pyplot as plt\n",
    "#   %matplotlib inline\n",
    "\n",
    "#   image = cv2.imread(path)\n",
    "#   height, width = image.shape[:2]\n",
    "#   resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#   fig = plt.gcf()\n",
    "#   fig.set_size_inches(18, 10)\n",
    "#   plt.axis(\"off\")\n",
    "#   plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "#   plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imShow('predicted/2fd875eaa_prediction.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top, left, bottom, right, mid_v, mid_h, label, scores\n",
    "# ObjectsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../input/global-wheat-detection/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'PredictionString'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aac893a91\n",
      "51f1be19e\n",
      "f5a1f0358\n",
      "796707dd7\n",
      "51b3e36ab\n",
      "348a992bb\n",
      "cc3532ff6\n",
      "2fd875eaa\n",
      "cb8d261a3\n",
      "53f253011\n",
      "babyflat\n"
     ]
    }
   ],
   "source": [
    "for index, row in submission_df.iterrows():\n",
    "    print(row['image_id'])\n",
    "    image_name = '../input/global-wheat-detection/test/'+row['image_id']+'.jpg'\n",
    "    r_image, ObjectsList = yolo.detect_img(image_name)\n",
    "    cv2.imwrite('predicted/'+row['image_id']+'.jpg', r_image)\n",
    "#     print(ObjectsList)\n",
    "    ObjectsDictList=[]\n",
    "    for prediction in ObjectsList:\n",
    "        predictionDict = {}\n",
    "        #top, left, bottom, right, mid_v, mid_h, label, scores\n",
    "        predictionDict[\"confidence\"]=prediction[7]\n",
    "        predictionDict[\"xmin\"]=prediction[1]\n",
    "        predictionDict[\"ymin\"]=prediction[0]\n",
    "        predictionDict[\"width\"]=prediction[3]-prediction[1]\n",
    "        predictionDict[\"height\"]=prediction[2]-prediction[0]\n",
    "        ObjectsDictList.append(predictionDict)\n",
    "    \n",
    "    ObjectsDictList=sorted(ObjectsDictList, key = lambda i: i['confidence'],reverse=True)\n",
    "    predictionString=\"\"\n",
    "    \n",
    "    for ObjectsDict in ObjectsDictList:\n",
    "        predictionString+=(str(ObjectsDict['confidence'])+\" \"\n",
    "                           +str(ObjectsDict[\"xmin\"])+\" \"\n",
    "                           +str(ObjectsDict[\"ymin\"])+\" \"\n",
    "                           +str(ObjectsDict[\"width\"])+\" \"\n",
    "                           +str(ObjectsDict[\"height\"])+\" \")\n",
    "    \n",
    "    predictionString=predictionString.strip()\n",
    "    \n",
    "    if(len(predictionString)!=0):\n",
    "        submission_df.loc[index,\"PredictionString\"]=predictionString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
